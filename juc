一、	Synchronized、wait()和notify()
1.	在调用wait()时，线程必须要持有被调用对象的锁。当调用wait()之后，线程会释放掉改对象的锁（monitor）
1）	在调用Thread类的sleep()时，线程是不会释放掉对象的锁的
2）	
2.	关于wait()、notify()和notifyAll()的总结
1）	当调用了wait()时，首先要确保调用了wait()的线程已经持有了对象的锁
2）	当调用了wait()后，该线程就会释放掉这个对象的锁，然后进入到等待状态（wait set）
3）	当线程调用了wait()后进入等待状态时，它就可以等待其他线程调用相同对象的notify()或notifyAll()来使得自己被唤醒
4）	一旦这个线程被其他线程唤醒后，该线程就会与其他线程一同开始竞争这个对象的锁（公平竞争）；只有该线程获取到了这个对象的锁后，线程才会往下执行调用wait()的代码片段需要放在一个synchronized块或是synchronized方法中，这样才可以确保线程在调用wait()前已经获得了对象的锁
5）	当调用了对象的notify()时，它会随机唤醒对象等待集合（wait set）中的任意一个线程。当某个线程被唤醒后，又会开始竞争对象的锁
6）	当调用对象的notifyAll()时，它会唤醒该对象等待集合（wait set）中的所有线程。这些线程被唤醒后，又会开始竞争对象的锁
7）	在某一时刻，只有唯一一个线程可以拥有对象的锁。
8）	
3.	Synchronized
1）	当一个类中一个静态方法被synchronized关键字修饰时，当一个线程访问某一个对象的synchronized、static方法时，获取到的不是这个对象的锁，而是这个对象所对象的Class对象的锁。
	本质上来说一个静态方法并不属于当前对象，它是属于当前对象所对应的class对象
2）	当某一个类中有若干个普通的synchronized方法，这些方法在某一时刻被多个线程所访问时，只能有一个方法被线程调用。因为当一个线程进入一个synchronized方法时，它首先要获取到当前对象的锁。同一类的两个不同实例他们的锁没有任何关系。第一个线程拿到第一个对象的锁，不影响第二个线程拿到另一个对象的锁
3）	当一个类中有一个synchronized、static方法时，当线程进入到这个方法时，线程锁获取的不是这个对象的锁，而是当前对象所对象的class对象的锁
4）	当前对象所对应的类不管有多少个对象，他们所对应的class对象只有唯一一个。它是类的反射的根源
5）	Synchronized关键字上锁
	Synchronized修饰代码块或者实例方法时，是给当前synchronize代码块或方法所在的对象上锁
	Synchronized修饰静态方法时是给这个对象所对应类的Class对象上锁
6）	当我们使用synchronized关键字来修饰代码块时，字节码层面上是通过monitorenter和monitorexit指令来实现的锁的获取与释放操作。一个monitorenter可能对应多个monitorexit。
	当线程进入monitorenter指令后，线程将会持有monitor对象，退出monitorenter指令后，线程将会释放monitor对象。
7）	对于synchronized关键字修饰方法来说，并没有出现monitorenter和monitorexit指令，而是出现了一个ACC_SYNCHRONIZED标志。
	JVM使用ACC_SYNCHRONIZED访问标志来区分一个方法是否为同步方法
	当方法被调用时，调用指令会检查该方法是拥有ACC_SYNCHRONIZED标志，如果有，那么执行线程将会先持有方法所在对象的monitor对象，然后再去执行方法体。在该方法执行期间，其他任何线程均无法在获取到这个对象的monitor对象。
4.	JVM中的同步是基于进入与退出监视器对象（管程对象）（Monitor）来实现的。每个对象实例都会有一个monitor对象，Monitor对象会和Java对象一同创建并销毁。Monitor对象是由C++来实现的。
1）	当多个线程同时访问一段同步代码时，这些线程会被放到一个EntryList集合中，处于阻塞状态的线程都会被放到该列表当中。接下来，当线程获取到对象的monitor时，monitor是依赖于底层操作系统的mutex lock来实现互斥的，线程获取metux成功，则会持有该mutex，这时其他线程就无法再获取改mutex. 依赖于底层操作系统提供的互斥锁得以实现
2）	如果线程调用了wait()，那么该线程就会释放掉所持有的的mutex，并且该线程会进入到WaitSet集合（等待集合）中，等待下一次被其他线程调用notify()/notifyAll()唤醒。如果当前线程顺利执行完毕方法，那么它也会释放掉所持有的的mutex
	线程进入WaitSet的时机：线程明确调用了wait()
	如果WaitSet集合中的线程被唤醒时，就会进入EntryList集合中，等待获取对象的mutex
	EntryList集合表示的是：等待着获取对象锁的线程。换言之，它们是处于阻塞状态下的线程。（存放准备去获取当前对象的锁，但是没有获取到的线程）
	EntryList（阻塞列表）和WaitSet（等待集合）都是monitor的成员变量，存放的线程都处于阻塞状态
3）	总结：同步锁在这种实现方法当中，因为monitor是依赖于底层操作系统实现，这样就存在用户态与内核态之间的切换，所以会增加性能开销。通过对象互斥锁的概念来保证共享数据操作的完整性。每个对象都对应一个可称为‘互斥锁’的标记，这个标记用于保证在任何时刻只能有一个线程访问该对象。
	当线程正在去执行业务代码的时候，它是处于用户态的状态之下。当线程尝试去获取某个对象的锁，但是这个对象的锁被另外一个线程已经持有了，并且还没有被释放掉，那么这个线程就会进入等待的状态，而等待的状态完全是由底层操作系统的mutex lock来实现的。所以一旦线程陷入阻塞或者等待的状态下，它就会立刻进入内核态。当这个线程又去尝试去获取这个对象的锁，并且能成功获取到这个对象的锁时，就会从内核态进入到用户态。这种切换是会增加性能开销的。
	针对这种情况JVM采取了一些优化的措施
	如果某一个对象的monitor已经被A线程持有了，并且A线程正在执行，那么B线程尝试去获取对象的monitor时，肯定是获取不到的，按照常规的理解，B线程就会立刻陷入等待集合当中。换句话来说，B线程就会发生从用户态进入内核态的切换。但是JVM会对这种情况做一些优化。如果A线程能很快执行完，就不会让B线程立刻进入内核态，而是让B线程就进行自旋，等待A线程释放monitor。自旋会占用CPU的资源，因为B线程自旋时还是处于运行的状态，而线程一定是运行在CPU之上的。若经过很短的时间后，A线程执行完释放掉对象的monitor，则B线程就有机会拿到对象的monitor，就可以正常往下执行。由于在等待的过程中，B线程并没有进入阻塞的状态，而是进入一种自旋的状态，所以始终都是处于在用户态下执行，并没有进入内核态，所以不会发生用户态和内核态之间的切换。
	但是自旋也会存在一个问题：A线程执行时间很长，这种情况下如果B线程自旋的话，会自旋很长一段时间，是对CPU资源的浪费（自旋啥也不做，就是为了等待A线程释放掉monitor）。因此当B自旋一定时间后还获取不到对象的锁，依然是会进入阻塞状态，发生用户态和内核态之间的切换。
	那些处于EntryList和WaitSet中的线程均处于阻塞状态，阻塞操作是由操作系统来完成的，在Linux下是通过pthread_mutex_lock函数实现的。线程被阻塞后便会进入到内核调度状态，这会导致系统在用户态与内核态之间来回切换，严重影响锁的性能。
	解决上述问题的办法就是自旋。其原理是：当发生对monitor的争用时，若owner能在很短的时间内释放掉锁，则那些正在争用的线程就可以稍微等待一下（所谓的自旋 spin）。在owner释放掉锁之后，争用线程可能会立刻获取到锁，从而避免了系统阻塞
	不过，当owner运行的时间超过了临界值后，争用线程自旋一段时间后依然无法获取到锁，这时争用线程则会停止自旋而进入阻塞状态。所以总体的思想是：先自旋，不成功再进行阻塞，尽量降低阻塞的可能性。这对那些执行时间很短的代码来说有极大的性能提高。显然，自旋在多处理器（多核心）上才有意义。
	
4）	互斥锁的属性（从操作系统底层来看，互斥锁包含一下四种类型。）
	PTHREAD_MUTEX_TIME_NP：这是缺省值，也就是普通锁。当一个线程加锁以后，其余请求锁的线程将会形成一个等待队列，并且在解锁后按照优先级获取到锁。这种策略可以确保分配到资源的公平性。
	PTHREAD_MUTEX_RECURSIVE_NP：嵌套锁（在Java中称为可重入锁）。允许同一个线程对同一个锁成功获取多次，并通过unlock解锁（加锁和解锁的次数必须一致）。如果是不同线程请求，则在加锁的线程解锁时重新进行竞争。
	PTHREAD_MUTEX_ERRORCHECK_NP：检错锁。如果一个线程请求同一个锁，则返回EDEADLK，否则与PTHREAD_MUTEX_TIME_NP类型动作相同，这样就保证了当不允许多次加锁时不会出现最简单情况下的死锁。
	PTHREAD_MUTEX_ADAPTIVE_NP：适应锁。动作就简单的锁，仅仅等待解锁后重新竞争（不管优先级，所有线程优先级都一样）。
5）	Synchronized关键字本身是由语言本身所提供的一个关键字，它跟jdk1.5之后提供的所谓的lock接口这些组件是完全不一样的实现方式。Synchronized关键字是通过语言的层面来去解决并发或者同步的一些问题。在jdk1.5之前，只能使用synchronized来实现同步或并发，没有其他选择。
 Jdk1.5之后增加的新的并发包里面包含了一些与lock相关的概念，在代码上显式加锁和解锁。这些动作本身是通过jdk层面上（jdk 库、类、接口）帮助实现的。但synchronized关键字完全是语言层面来实现的（关键字），关键字真正落实到字节码上时，本质上还是要通过底层的操作系统提供的一些关于同步、访问互斥资源的一些属性来实现的，且在不同的操作系统上的实现是不相同的。语言本身加上关键字之后，Java编译器在编译我们的程序代码时，当它遇到这样的关键字就会生成对应的一些字节码（如monitorenter、monitorexit或ACC_SYNCHRONIZED）等一些指令，最终映射成底层操作系统的函数调用。
6）	
7）	
5.	查看JDK源码：openJDK   openjdk.java.net
二、	锁
1.	ThreadLocalMap的实现使用了弱引用。弱引用是比强引用弱得多的引用，Java虚拟机在垃圾回收时，如果发现弱引用，就立即回收。
1）	ThreadLocalMap内部由一系列Entry构成，每一个Entry都是WeakReference<ThreadLocal>
2）	如果共享对象对于竞争的处理容易因此性能损失，我们还是应该考虑使用ThreadLocal为每个线程分配单独的对象。
2.	无锁
1）	对于并发控制而言，锁是一种悲观的策略。它总是假设每一次临界区操作会产生冲突。因此，必须对每次操作都小心翼翼。
 如果有多个线程同时需要访问临界区资源，就宁可牺牲性能让线程进行等待。所以说锁会阻塞线程执行。
 无锁是一种乐观策略，它会假设对资源的访问是没有冲突的。既然没有冲突，自然不需要等待，所以所有的线程都可以在不停顿的状态下持续执行。无锁的策略使用一种叫做比较技术（CAS comare and swap）来鉴别线程冲突，一旦检查到冲突发生，就重试当前操作直到没有冲突为止。
2）	与众不同的并发策略：比较交换（CAS compare and swap）
	由于其非阻塞性，它对死锁问题天生免疫，且没有锁竞争带来的系统开销。
	CAS算法的过程：
	包含三个参数 CAS(V, E, N)，V：表示要更新的变量，E：表示预期值，N：表示新值。
	仅当V值等于E值时，才会将V的值设为N
	如果V值不等于E值，则说明已经有其他线程做了更新，则当前线程什么也不做。
	最后，CAS返回当前V的真实值。
	CAS操作是抱着乐观的态度进行的，它总认为自己可以成功完成操作。当有多个线程同时使用CAS操作一个变量时，至于一个会胜出，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并且允许再次尝试或放弃操作。
3）	无锁的线程安全整数：AtomicInteger
	可以看作一个整数，但与Integer不同的是它是可变的，并且是线程安全的
	对其进行修改等任何操作，都是用CAS指令进行。
3.	Java中的指针：Unsafe类
1）	sun.misc.Unsafe类封装了一些类似指针的操作。
2）	例如如下操作
public final native boolean compareAndSwapInt(Object var1, long offset, int expect, int x);
	o：给定的对象
	offset：一个字段到对象头部的偏移量，通过这个偏移量可以快速定位字段
	expect表示期望值
	x要设置的值
3）	Unsaf只能在JDK内部使用，因为在获取Unsafe对象时，会判断获取的类的类加载器是否是根类加载器，如果不是则不能获取。
4.	无锁对象的引用：AtomicReference
1）	AtomicReference是对普通引用的封装，它可以保证你在修改对象引用时的线程安全性。
2）	这个无法解决一个对象被多次修改后，最终改回了我的期望值的情况，符号我进行修改的情况。即修改的对象没有过程的状态信息，所有的信息都只保存于对象的数值本身
5.	带有时间戳的对象引用：AtomicStampedReference
1）	我们只要能够记录对象在修改过程中的状态值，就可以很好地解决对象被反复修改导致线程无法正确判断对象状态的问题。
2）	AtomicStampedReference内部不仅维护了对象值，还维护了一个时间戳（问么这里把它称为时间戳，实际上它可以使用任何一个整数来表示状态值）
3）	更新对象值时，必须要更新时间错
6.	无锁数组：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray
7.	普通变量原子性操作：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater，他们可以分别对int、long和普通对象进行CAS修改。
8.	无锁的Vector实现
9.	让线程之间互相帮助：细看SynchronizedQueue的实现
1）	SynchronousQueue的容量为0。任何一个对SynchronousQueue的写需要等待一个对SynchronousQueue的读，反之亦然。因此，SynchronousQueue与其说是一个队列，不如说是一个数据交换的通道。
2）	SynchronousQueue底层大量使用了无锁工具，它将put()和take()两个功能截然不同的操作抽象为一个共通的方法Transferer.transfer()。
	完整签名：E transfer(E e, boolean timed, long nanos);
	当参数e非空时，表示当前操作传递给一个消费者。如果为空，则表示当前操作需要请求一个数据。
	timed参数决定是否存在timeout时间
	nanos决定了timeout的时长。
	如果返回值非空，则表示正常数据已经接收或者正常提供。如果为空，则表示失败（超时或者中断）
3）	SynchronousQueue内部会维护一个线程等待队列。等待队列中户保存等待线程以及相关数据的信息。
	如，生产者将数据放入SynchronousQueue时，如果没有消费者接收，那么数据本身和线程对象都会打包在队列中等待（因为SynchronousQueue容积为0，没有数据可以正常放入）
4）	Transferer.transfer()的实现是SynchronousQueue的核心，它大体上分为三个步骤
	如果等待队列为空，或者队列中节点的类型和本次操作是一致的，那么将当前操作压入队列中等待。
	例如：等待队列中是读线程等待，本次操作也是读，因此这两个读都需要等待。
	进入等待队列的线程可能会被挂起，他们会等待一个“匹配”操作
	如果等待队列中的元素和本次操作是互补的那么及插入一个“完成”状态的节点，并且让它“匹配”到一个等待节点上。接着弹出这两个节点，并且使得对应的两个线程继续执行。
	例如：等待操作是读，而本次操作是写
	如果线程发现等待队列的节点就是“完成”节点，那么帮助这个节点完成任务。其流程和步骤2是一致的。
5）	
10.	
三、	


